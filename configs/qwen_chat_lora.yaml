# configs/lora/qwen_chat_lora.yaml
# Qwen 聊天模型 LoRA 微調配置

model:
  name: "Qwen/Qwen2-7B-Instruct"
  type: "text_generation"  # text_generation | vision_text

lora:
  r: 16                    # LoRA rank (4, 8, 16, 32)
  alpha: 32                # LoRA alpha (通常是 r 的 2 倍)
  dropout: 0.1             # LoRA dropout
  target_modules:          # 目標模組
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: "none"             # none | all | lora_only

data:
  path: "data/training/chat_dataset.jsonl"
  format: "jsonl"          # json | jsonl | csv

  # 數據格式範例:
  # {"input": "用戶問題", "output": "助手回答"}

training:
  output_dir: "models/lora/qwen-chat-v1"
  epochs: 3
  batch_size: 4
  eval_batch_size: 4
  learning_rate: 2e-4
  weight_decay: 0.01
  max_length: 512
  logging_steps: 10
  eval_steps: 100
  save_steps: 200
  warmup_ratio: 0.1

  # 梯度累積 (有效 batch size = batch_size * gradient_accumulation_steps)
  gradient_accumulation_steps: 4

  # 混合精度訓練
  fp16: true
  dataloader_num_workers: 4

# configs/lora/blip2_caption_lora.yaml
# BLIP-2 圖像描述 LoRA 微調配置

model:
  name: "Salesforce/blip2-opt-2.7b"
  type: "vision_text"

lora:
  r: 8
  alpha: 16
  dropout: 0.1
  target_modules:
    - "q_proj"
    - "v_proj"
    - "qkv"
  bias: "none"

data:
  path: "data/training/caption_dataset.jsonl"
  format: "jsonl"

  # 數據格式範例:
  # {"image_path": "path/to/image.jpg", "caption": "圖像描述"}

training:
  output_dir: "models/lora/blip2-caption-v1"
  epochs: 5
  batch_size: 2          # 視覺模型記憶體需求較大
  eval_batch_size: 2
  learning_rate: 1e-4
  weight_decay: 0.01
  max_length: 128        # 較短的描述長度
  logging_steps: 20
  eval_steps: 200
  save_steps: 400
  gradient_accumulation_steps: 8
  fp16: true

# configs/lora/domain_specific_lora.yaml
# 領域特化 LoRA 配置範例

model:
  name: "Qwen/Qwen2-7B-Instruct"
  type: "text_generation"

lora:
  r: 32                    # 較高的 rank 用於複雜任務
  alpha: 64
  dropout: 0.05            # 較低的 dropout
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"

data:
  path: "data/training/medical_qa.jsonl"  # 醫療問答範例
  format: "jsonl"

training:
  output_dir: "models/lora/qwen-medical-v1"
  epochs: 5
  batch_size: 2
  eval_batch_size: 4
  learning_rate: 1e-4      # 較低的學習率用於穩定訓練
  weight_decay: 0.05
  max_length: 1024         # 較長的上下文用於複雜問答
  logging_steps: 5
  eval_steps: 50
  save_steps: 100
  gradient_accumulation_steps: 16
  warmup_ratio: 0.05
  fp16: true

# 高級訓練選項
advanced:
  use_gradient_checkpointing: true    # 節省記憶體
  ddp_find_unused_parameters: false   # 分散式訓練優化
  remove_unused_columns: false        # 保留數據欄位
  prediction_loss_only: true          # 僅計算預測損失